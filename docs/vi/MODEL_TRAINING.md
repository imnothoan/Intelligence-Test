# H∆∞·ªõng D·∫´n Training v√† S·ª≠ D·ª•ng AI Models

> üî• **QUAN TR·ªåNG**: N·∫øu b·∫°n l√† ng∆∞·ªùi m·ªõi, h√£y ƒë·ªçc **[TUTORIAL_TRAINING.vi.md](./TUTORIAL_TRAINING.vi.md)** tr∆∞·ªõc ƒë·ªÉ c√≥ h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc chi ti·∫øt!

## ‚ùì C√ÇU H·ªéI TH∆Ø·ªúNG G·∫∂P (ƒê·ªåC TR∆Ø·ªöC KHI B·∫ÆT ƒê·∫¶U)

### 1. T√¥i c√≥ c·∫ßn train AI model kh√¥ng?
**‚ùå KH√îNG** - Trong h·∫ßu h·∫øt c√°c tr∆∞·ªùng h·ª£p, b·∫°n **KH√îNG C·∫¶N** train b·∫•t k·ª≥ model n√†o!

H·ªá th·ªëng ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng v·ªõi:
- ‚úÖ AI sinh c√¢u h·ªèi: D√πng API (Gemini mi·ªÖn ph√≠, OpenAI tr·∫£ ph√≠, ho·∫∑c Ollama local)
- ‚úÖ AI ch·∫•m t·ª± lu·∫≠n: D√πng API (t∆∞∆°ng t·ª± tr√™n)
- ‚úÖ AI ph√°t hi·ªán gian l·∫≠n: BlazeFace ƒë√£ t√≠ch h·ª£p s·∫µn

**Ch·ªâ c·∫ßn train khi:**
- Mu·ªën custom model anti-cheat cho m√¥i tr∆∞·ªùng ƒë·∫∑c bi·ªát
- ƒê√£ c√≥ >100 h·ªçc sinh v√† mu·ªën calibrate ƒë·ªô kh√≥ c√¢u h·ªèi ch√≠nh x√°c h∆°n

### 2. T√¥i train ·ªü ƒë√¢u?
**Tr·∫£ l·ªùi:** Train ngay tr√™n m√°y c·ªßa b·∫°n trong folder project:
```
Intelligence-Test/
‚îú‚îÄ‚îÄ training/           ‚Üê T·∫†O folder n√†y ƒë·ªÉ train
‚îÇ   ‚îú‚îÄ‚îÄ anticheat/     ‚Üê Train anti-cheat model
‚îÇ   ‚îî‚îÄ‚îÄ cat/           ‚Üê Calibrate CAT algorithm
```

### 3. Dataset l·∫•y ·ªü ƒë√¢u?
**Tr·∫£ l·ªùi:**
- **AI sinh c√¢u h·ªèi**: Kh√¥ng c·∫ßn dataset, ch·ªâ c·∫ßn API key
- **Anti-cheat**: T·ª± thu th·∫≠p qua webcam (script c√≥ s·∫µn)
- **CAT calibration**: Export d·ªØ li·ªáu h·ªçc sinh t·ª´ app

### 4. Sau khi train xong, l√†m th·∫ø n√†o ƒë·ªÉ d√πng?
**Tr·∫£ l·ªùi:**
1. Model train xong ‚Üí Convert sang TensorFlow.js (n·∫øu l√† anti-cheat)
2. Copy file model v√†o `public/models/` trong project
3. App t·ª± ƒë·ªông load model t·ª´ folder ƒë√≥
4. Kh√¥ng c·∫ßn l√†m g√¨ th√™m!

### 5. T√¥i kh√¥ng bi·∫øt Python/ML, c√≥ d√πng ƒë∆∞·ª£c app kh√¥ng?
**‚úÖ C√ì!** H·ªá th·ªëng ho·∫°t ƒë·ªông ho√†n to√†n b√¨nh th∆∞·ªùng kh√¥ng c·∫ßn training. Ch·ªâ c·∫ßn:
```bash
npm install
npm run dev
```

### 6. T√¥i mu·ªën d√πng AI ƒë·ªÉ t·∫°o c√¢u h·ªèi, ph·∫£i l√†m g√¨?
**Tr·∫£ l·ªùi:** 
1. L·∫•y API key mi·ªÖn ph√≠ t·ª´ [Google Gemini](https://makersuite.google.com/app/apikey)
2. Th√™m v√†o file `.env`: `VITE_GEMINI_API_KEY=your_key`
3. C√†i package: `npm install @google/generative-ai`
4. Xong! D√πng n√∫t "Generate Question" trong app

---

## M·ª•c L·ª•c
1. [T·ªïng Quan](#t·ªïng-quan)
2. [Model CAT Algorithm](#model-cat-algorithm)
3. [Model Sinh C√¢u H·ªèi (Question Generation)](#model-sinh-c√¢u-h·ªèi)
4. [Model Anti-Cheat](#model-anti-cheat)
5. [T√≠ch H·ª£p LLM APIs](#t√≠ch-h·ª£p-llm-apis)

---

## T·ªïng Quan

H·ªá th·ªëng Intelligence Test s·ª≠ d·ª•ng nhi·ªÅu lo·∫°i AI models:

| Model | C√¥ng d·ª•ng | C√¥ng ngh·ªá | Training c·∫ßn thi·∫øt |
|-------|-----------|-----------|-------------------|
| CAT Algorithm | Adaptive testing | IRT (Item Response Theory) | C√≥ - calibrate c√¢u h·ªèi |
| Question Generation | T·∫°o c√¢u h·ªèi t·ª± ƒë·ªông | LLM API (GPT, Gemini) | Kh√¥ng - d√πng API |
| Essay Grading | Ch·∫•m b√†i t·ª± lu·∫≠n | LLM API | Kh√¥ng - d√πng API |
| Anti-Cheat | Ph√°t hi·ªán gian l·∫≠n | Computer Vision | C√≥ - train custom model |

---

## Model CAT Algorithm

### Gi·ªõi Thi·ªáu

CAT (Computerized Adaptive Testing) s·ª≠ d·ª•ng **Item Response Theory (IRT)** ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªô kh√≥ c√¢u h·ªèi d·ª±a tr√™n kh·∫£ nƒÉng c·ªßa h·ªçc sinh.

### C√°ch Ho·∫°t ƒê·ªông

**1PL IRT Model (Rasch Model):**
```
P(correct) = 1 / (1 + exp(-(ability - difficulty)))
```

- `ability`: Kh·∫£ nƒÉng c·ªßa h·ªçc sinh (Œ∏)
- `difficulty`: ƒê·ªô kh√≥ c·ªßa c√¢u h·ªèi (b)

### Kh√¥ng C·∫ßn Training Model (Built-in)

H·ªá th·ªëng ƒë√£ c√≥ s·∫µn CAT algorithm, KH√îNG c·∫ßn train model ri√™ng. Ch·ªâ c·∫ßn:

**B∆∞·ªõc 1: G√°n ƒë·ªô kh√≥ cho c√¢u h·ªèi**
- 0.0 - 0.3: D·ªÖ
- 0.3 - 0.7: Trung b√¨nh
- 0.7 - 1.0: Kh√≥

**B∆∞·ªõc 2: H·ªá th·ªëng t·ª± ƒë·ªông**
- Ch·ªçn c√¢u h·ªèi ph√π h·ª£p
- ∆Ø·ªõc t√≠nh ability
- ƒêi·ªÅu ch·ªânh ƒë·ªô kh√≥

### Calibration N√¢ng Cao (Optional)

N·∫øu mu·ªën calibrate ƒë·ªô kh√≥ CH√çNH X√ÅC h∆°n d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø:

#### Y√™u C·∫ßu
- Python 3.8+
- √çt nh·∫•t 100-200 responses m·ªói c√¢u h·ªèi
- D·ªØ li·ªáu l·ªãch s·ª≠ thi

#### B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu

T·∫°o file `responses.csv`:
```csv
student_id,question_id,correct,time_taken
S001,Q001,1,45
S001,Q002,0,60
S002,Q001,1,50
S002,Q002,1,55
...
```

#### B∆∞·ªõc 2: C√†i ƒë·∫∑t Python packages

```bash
pip install numpy scipy pandas scikit-learn
```

#### B∆∞·ªõc 3: T·∫°o script training

T·∫°o file `train_cat_model.py`:

```python
import pandas as pd
import numpy as np
from scipy.optimize import minimize

def rasch_probability(ability, difficulty):
    """T√≠nh x√°c su·∫•t tr·∫£ l·ªùi ƒë√∫ng theo Rasch model"""
    return 1 / (1 + np.exp(-(ability - difficulty)))

def log_likelihood(params, responses):
    """H√†m log-likelihood ƒë·ªÉ t·ªëi ∆∞u"""
    n_students = len(set(responses['student_id']))
    n_questions = len(set(responses['question_id']))
    
    abilities = params[:n_students]
    difficulties = params[n_students:]
    
    ll = 0
    for _, row in responses.iterrows():
        student_idx = row['student_idx']
        question_idx = row['question_idx']
        correct = row['correct']
        
        prob = rasch_probability(abilities[student_idx], difficulties[question_idx])
        ll += correct * np.log(prob) + (1 - correct) * np.log(1 - prob)
    
    return -ll  # Negative for minimization

def calibrate_questions(csv_file):
    """Calibrate ƒë·ªô kh√≥ c√¢u h·ªèi t·ª´ d·ªØ li·ªáu"""
    # ƒê·ªçc d·ªØ li·ªáu
    df = pd.read_csv(csv_file)
    
    # Map IDs sang indices
    students = df['student_id'].unique()
    questions = df['question_id'].unique()
    
    student_map = {s: i for i, s in enumerate(students)}
    question_map = {q: i for i, q in enumerate(questions)}
    
    df['student_idx'] = df['student_id'].map(student_map)
    df['question_idx'] = df['question_id'].map(question_map)
    
    # Initial parameters (random)
    n_students = len(students)
    n_questions = len(questions)
    initial_params = np.random.randn(n_students + n_questions) * 0.1
    
    # Optimize
    print("Training IRT model...")
    result = minimize(
        log_likelihood,
        initial_params,
        args=(df,),
        method='BFGS',
        options={'maxiter': 1000, 'disp': True}
    )
    
    # Extract parameters
    abilities = result.x[:n_students]
    difficulties = result.x[n_students:]
    
    # Normalize difficulties to 0-1 range
    min_diff = difficulties.min()
    max_diff = difficulties.max()
    normalized_difficulties = (difficulties - min_diff) / (max_diff - min_diff)
    
    # Save results
    results = pd.DataFrame({
        'question_id': questions,
        'difficulty': normalized_difficulties,
        'raw_difficulty': difficulties
    })
    
    results.to_csv('calibrated_difficulties.csv', index=False)
    print(f"\nCalibration complete!")
    print(f"Results saved to: calibrated_difficulties.csv")
    
    return results

if __name__ == '__main__':
    import sys
    if len(sys.argv) < 2:
        print("Usage: python train_cat_model.py <responses.csv>")
        sys.exit(1)
    
    results = calibrate_questions(sys.argv[1])
    print("\nSample results:")
    print(results.head(10))
```

#### B∆∞·ªõc 4: Ch·∫°y training

```bash
python train_cat_model.py responses.csv
```

Output: `calibrated_difficulties.csv` v·ªõi ƒë·ªô kh√≥ ƒë√£ ƒë∆∞·ª£c calibrate.

#### B∆∞·ªõc 5: Import v√†o h·ªá th·ªëng

1. V√†o **Question Bank** trong ·ª©ng d·ª•ng
2. Import/update c√°c c√¢u h·ªèi v·ªõi difficulty m·ªõi
3. Ho·∫∑c d√πng API/script ƒë·ªÉ bulk update

---

## Model Sinh C√¢u H·ªèi

### Kh√¥ng C·∫ßn Training - D√πng LLM API

H·ªá th·ªëng s·ª≠ d·ª•ng c√°c LLM c√≥ s·∫µn qua API. **KH√îNG c·∫ßn train model ri√™ng**.

### Option 1: OpenAI API (Tr·∫£ ph√≠, ch·∫•t l∆∞·ª£ng cao)

#### B∆∞·ªõc 1: ƒêƒÉng k√Ω API key
1. Truy c·∫≠p: https://platform.openai.com/signup
2. T·∫°o t√†i kho·∫£n v√† verify email
3. V√†o https://platform.openai.com/api-keys
4. Click "Create new secret key"
5. Copy key (b·∫Øt ƒë·∫ßu v·ªõi `sk-`)

#### B∆∞·ªõc 2: Th√™m v√†o .env
```env
VITE_OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxx
```

#### B∆∞·ªõc 3: S·ª≠ d·ª•ng trong app
- V√†o **Question Bank** ‚Üí **Generate Question**
- Nh·∫≠p topic v√† y√™u c·∫ßu
- H·ªá th·ªëng t·ª± ƒë·ªông g·ªçi OpenAI API

**Chi ph√≠:**
- GPT-3.5 Turbo: $0.001/1K tokens (~500 c√¢u h·ªèi/$1)
- GPT-4: $0.03/1K tokens (~17 c√¢u h·ªèi/$1)

### Option 2: Google Gemini API (Mi·ªÖn ph√≠, gi·ªõi h·∫°n)

#### B∆∞·ªõc 1: L·∫•y API key
1. Truy c·∫≠p: https://makersuite.google.com/app/apikey
2. Click "Get API key"
3. Ch·ªçn ho·∫∑c t·∫°o Google Cloud project
4. Copy API key

#### B∆∞·ªõc 2: C√†i ƒë·∫∑t package
```bash
npm install @google/generative-ai
```

#### B∆∞·ªõc 3: T·∫°o service wrapper

File `src/services/geminiService.ts`:

```typescript
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(import.meta.env.VITE_GEMINI_API_KEY || '');

export async function generateQuestion(topic: string, difficulty: string) {
  const model = genAI.getGenerativeModel({ model: 'gemini-pro' });
  
  const prompt = `Generate a ${difficulty} multiple-choice question about ${topic}.
Include:
1. Question text
2. Four answer options (A, B, C, D)
3. Correct answer
4. Brief explanation

Format as JSON.`;

  const result = await model.generateContent(prompt);
  const response = await result.response;
  const text = response.text();
  
  return JSON.parse(text);
}
```

#### B∆∞·ªõc 4: Update .env
```env
VITE_GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxx
```

**Gi·ªõi h·∫°n mi·ªÖn ph√≠:**
- 60 requests/ph√∫t
- 1,500 requests/ng√†y

### Option 3: Hugging Face (Mi·ªÖn ph√≠, open-source)

#### B∆∞·ªõc 1: L·∫•y token
1. Truy c·∫≠p: https://huggingface.co/settings/tokens
2. Create new token
3. Copy token

#### B∆∞·ªõc 2: C√†i ƒë·∫∑t
```bash
npm install @huggingface/inference
```

#### B∆∞·ªõc 3: T·∫°o service

File `src/services/huggingfaceService.ts`:

```typescript
import { HfInference } from '@huggingface/inference';

const hf = new HfInference(import.meta.env.VITE_HF_TOKEN);

export async function generateQuestion(topic: string, difficulty: string) {
  const response = await hf.textGeneration({
    model: 'mistralai/Mistral-7B-Instruct-v0.1',
    inputs: `Generate a ${difficulty} multiple-choice question about ${topic}...`,
    parameters: {
      max_new_tokens: 500,
      temperature: 0.7,
    }
  });
  
  return parseQuestionFromText(response.generated_text);
}
```

### Option 4: Ollama (Local, ho√†n to√†n mi·ªÖn ph√≠)

#### B∆∞·ªõc 1: C√†i ƒë·∫∑t Ollama
```bash
# MacOS/Linux
curl https://ollama.ai/install.sh | sh

# Windows: Download t·ª´ ollama.ai
```

#### B∆∞·ªõc 2: Pull model
```bash
ollama pull llama2
# Ho·∫∑c: ollama pull mistral
```

#### B∆∞·ªõc 3: Start server
```bash
ollama serve
```

#### B∆∞·ªõc 4: S·ª≠ d·ª•ng trong app

```typescript
async function generateQuestion(topic: string, difficulty: string) {
  const response = await fetch('http://localhost:11434/api/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: 'llama2',
      prompt: `Generate a ${difficulty} question about ${topic}...`,
      stream: false
    })
  });
  
  const data = await response.json();
  return parseQuestionFromText(data.response);
}
```

**∆Øu ƒëi·ªÉm:**
- Ho√†n to√†n mi·ªÖn ph√≠
- Kh√¥ng gi·ªõi h·∫°n requests
- Privacy (ch·∫°y local)

**Nh∆∞·ª£c ƒëi·ªÉm:**
- C·∫ßn m√°y m·∫°nh (8GB+ RAM)
- Ch·∫•t l∆∞·ª£ng th·∫•p h∆°n GPT-4

---

## Model Anti-Cheat

### Overview

Model Anti-Cheat s·ª≠ d·ª•ng Computer Vision ƒë·ªÉ ph√°t hi·ªán:
- Kh√¥ng c√≥ ng∆∞·ªùi tr∆∞·ªõc camera
- Nhi·ªÅu ng∆∞·ªùi c√πng l√∫c
- Nh√¨n sang ch·ªó kh√°c
- Di chuy·ªÉn b·∫•t th∆∞·ªùng

### Built-in Model (BlazeFace)

H·ªá th·ªëng ƒë√£ t√≠ch h·ª£p s·∫µn **BlazeFace** t·ª´ TensorFlow.js:
- Detect faces
- Track head position
- Kh√¥ng c·∫ßn training

### Training Custom Model (N√¢ng cao)

N·∫øu mu·ªën model ch√≠nh x√°c h∆°n cho tr∆∞·ªùng h·ª£p c·ª• th·ªÉ:

#### Y√™u C·∫ßu
- Python 3.8+
- TensorFlow 2.x
- Webcam ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu
- GPU khuy·∫øn ngh·ªã (kh√¥ng b·∫Øt bu·ªôc)

#### B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu

T·∫°o script `collect_data.py`:

```python
import cv2
import os
from datetime import datetime

def collect_training_data(output_dir, label):
    """Thu th·∫≠p ·∫£nh training data"""
    os.makedirs(output_dir, exist_ok=True)
    
    cap = cv2.VideoCapture(0)
    count = 0
    
    print(f"Collecting {label} data...")
    print("Press SPACE to capture, Q to quit")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        cv2.imshow('Collect Data', frame)
        
        key = cv2.waitKey(1)
        if key == ord(' '):  # Space to capture
            filename = f"{label}_{count:04d}.jpg"
            filepath = os.path.join(output_dir, filename)
            cv2.imwrite(filepath, frame)
            print(f"Saved: {filename}")
            count += 1
            
        elif key == ord('q'):  # Q to quit
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print(f"Collected {count} images")

if __name__ == '__main__':
    # Collect normal behavior
    print("\n=== NORMAL BEHAVIOR ===")
    print("Looking at screen, minimal movement")
    collect_training_data('data/normal', 'normal')
    
    # Collect cheating behavior
    print("\n=== CHEATING BEHAVIOR ===")
    print("Looking away, multiple people, etc.")
    collect_training_data('data/cheat', 'cheat')
```

**Ch·∫°y:**
```bash
python collect_data.py
```

Thu th·∫≠p:
- 500-1000 ·∫£nh "normal" (nh√¨n m√†n h√¨nh b√¨nh th∆∞·ªùng)
- 500-1000 ·∫£nh "cheat" (nh√¨n ƒëi ch·ªó kh√°c, nhi·ªÅu ng∆∞·ªùi, v.v.)

#### B∆∞·ªõc 2: Chu·∫©n b·ªã dataset

```python
# prepare_dataset.py
import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split

def load_images(directory, label):
    """Load v√† label images"""
    images = []
    labels = []
    
    for filename in os.listdir(directory):
        if filename.endswith('.jpg'):
            filepath = os.path.join(directory, filename)
            img = cv2.imread(filepath)
            img = cv2.resize(img, (224, 224))  # Resize to standard size
            img = img / 255.0  # Normalize
            
            images.append(img)
            labels.append(label)
    
    return np.array(images), np.array(labels)

def prepare_dataset():
    """Prepare training v√† validation sets"""
    # Load data
    normal_images, normal_labels = load_images('data/normal', 0)
    cheat_images, cheat_labels = load_images('data/cheat', 1)
    
    # Combine
    X = np.concatenate([normal_images, cheat_images])
    y = np.concatenate([normal_labels, cheat_labels])
    
    # Split
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Save
    np.save('data/X_train.npy', X_train)
    np.save('data/X_val.npy', X_val)
    np.save('data/y_train.npy', y_train)
    np.save('data/y_val.npy', y_val)
    
    print(f"Training set: {len(X_train)} images")
    print(f"Validation set: {len(X_val)} images")

if __name__ == '__main__':
    prepare_dataset()
```

#### B∆∞·ªõc 3: Training model

```python
# train_anticheat.py
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

def create_model():
    """Create CNN model cho anti-cheat"""
    model = keras.Sequential([
        # Input layer
        layers.Input(shape=(224, 224, 3)),
        
        # Convolutional blocks
        layers.Conv2D(32, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.BatchNormalization(),
        
        layers.Conv2D(64, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.BatchNormalization(),
        
        layers.Conv2D(128, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.BatchNormalization(),
        
        # Dense layers
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')  # Binary classification
    ])
    
    return model

def train_model():
    """Train anti-cheat model"""
    # Load data
    X_train = np.load('data/X_train.npy')
    y_train = np.load('data/y_train.npy')
    X_val = np.load('data/X_val.npy')
    y_val = np.load('data/y_val.npy')
    
    # Create model
    model = create_model()
    
    # Compile
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )
    
    # Callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            patience=10,
            restore_best_weights=True
        ),
        keras.callbacks.ModelCheckpoint(
            'models/anticheat_best.h5',
            save_best_only=True
        ),
        keras.callbacks.ReduceLROnPlateau(
            factor=0.5,
            patience=5
        )
    ]
    
    # Train
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=50,
        batch_size=32,
        callbacks=callbacks
    )
    
    # Save final model
    model.save('models/anticheat_final.h5')
    print("Training complete!")
    
    return model, history

if __name__ == '__main__':
    model, history = train_model()
    
    # Evaluate
    X_val = np.load('data/X_val.npy')
    y_val = np.load('data/y_val.npy')
    
    results = model.evaluate(X_val, y_val)
    print(f"\nValidation Results:")
    print(f"Loss: {results[0]:.4f}")
    print(f"Accuracy: {results[1]:.4f}")
    print(f"Precision: {results[2]:.4f}")
    print(f"Recall: {results[3]:.4f}")
```

**Ch·∫°y:**
```bash
pip install tensorflow opencv-python scikit-learn
python prepare_dataset.py
python train_anticheat.py
```

#### B∆∞·ªõc 4: Convert sang TensorFlow.js

```bash
pip install tensorflowjs

tensorflowjs_converter \
  --input_format=keras \
  models/anticheat_final.h5 \
  public/models/anticheat
```

S·∫Ω t·∫°o:
- `public/models/anticheat/model.json`
- `public/models/anticheat/group1-shard1of1.bin`

#### B∆∞·ªõc 5: T√≠ch h·ª£p v√†o app

Update `src/services/antiCheatService.ts`:

```typescript
import * as tf from '@tensorflow/tfjs';

export class AntiCheatService {
  private model: tf.LayersModel | null = null;
  
  async loadCustomModel() {
    // Load your custom model
    this.model = await tf.loadLayersModel('/models/anticheat/model.json');
    console.log('Custom anti-cheat model loaded');
  }
  
  async detectCheating(imageData: ImageData): Promise<boolean> {
    if (!this.model) {
      await this.loadCustomModel();
    }
    
    // Preprocess image
    const tensor = tf.browser.fromPixels(imageData)
      .resizeBilinear([224, 224])
      .div(255.0)
      .expandDims(0);
    
    // Predict
    const prediction = await this.model!.predict(tensor) as tf.Tensor;
    const score = await prediction.data();
    
    // Clean up
    tensor.dispose();
    prediction.dispose();
    
    // score > 0.5 means cheating detected
    return score[0] > 0.5;
  }
}
```

---

## T√≠ch H·ª£p LLM APIs

### So S√°nh C√°c Options

| Provider | Mi·ªÖn ph√≠ | Ch·∫•t l∆∞·ª£ng | T·ªëc ƒë·ªô | Privacy |
|----------|----------|------------|---------|---------|
| OpenAI GPT-4 | ‚ùå ($) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| OpenAI GPT-3.5 | ‚ùå ($) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Google Gemini | ‚úÖ (gi·ªõi h·∫°n) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Hugging Face | ‚úÖ | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Ollama (Local) | ‚úÖ | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

### Khuy·∫øn Ngh·ªã

**Cho production (tr·∫£ ph√≠):**
- OpenAI GPT-3.5 Turbo: T·ªët nh·∫•t v·ªÅ gi√°/ch·∫•t l∆∞·ª£ng
- OpenAI GPT-4: Cho essay grading ch·∫•t l∆∞·ª£ng cao

**Cho development/testing (mi·ªÖn ph√≠):**
- Google Gemini: T·ªët nh·∫•t trong c√°c option mi·ªÖn ph√≠
- Ollama: N·∫øu c√≥ m√°y m·∫°nh v√† c·∫ßn privacy

**Cho tr∆∞·ªùng h·ªçc nh·ªè (budget th·∫•p):**
- Gemini cho question generation
- BlazeFace (built-in) cho anti-cheat
- Manual grading cho essays

---

## Best Practices

### Question Generation
1. **Review tr∆∞·ªõc khi d√πng**: Lu√¥n ki·ªÉm tra c√¢u h·ªèi AI t·∫°o
2. **ƒêa d·∫°ng prompts**: Th·ª≠ nhi·ªÅu c√°ch h·ªèi kh√°c nhau
3. **Set temperature th·∫•p**: 0.3-0.5 cho consistent results
4. **Batch generation**: T·∫°o nhi·ªÅu c√¢u c√πng l√∫c ƒë·ªÉ ch·ªçn l·ªçc

### CAT Algorithm
1. **Start v·ªõi medium difficulty**: C√¢u ƒë·∫ßu n√™n ·ªü 0.5
2. **Minimum 10 questions**: √çt nh·∫•t 10 c√¢u cho accurate assessment
3. **Balanced question bank**: ƒê·ªß c√¢u h·ªèi ·ªü m·ªçi m·ª©c ƒë·ªô
4. **Regular calibration**: Update difficulties ƒë·ªãnh k·ª≥

### Anti-Cheat
1. **Inform students**: Th√¥ng b√°o tr∆∞·ªõc v·ªÅ monitoring
2. **Test tr∆∞·ªõc**: Test system v·ªõi m·ªôt nh√≥m nh·ªè
3. **Adjust sensitivity**: ƒêi·ªÅu ch·ªânh threshold ph√π h·ª£p
4. **Manual review**: Review c√°c warning c·∫©n th·∫≠n

### Cost Optimization
1. **Cache results**: Cache c√¢u h·ªèi ƒë√£ generate
2. **Use cheaper models**: GPT-3.5 thay v√¨ GPT-4 khi c√≥ th·ªÉ
3. **Batch requests**: G·ªôp nhi·ªÅu requests l·∫°i
4. **Local models**: D√πng Ollama cho non-critical tasks

---

## Troubleshooting

### LLM API kh√¥ng ho·∫°t ƒë·ªông
**Ki·ªÉm tra:**
- API key ƒë√∫ng ch∆∞a
- C√≤n credit kh√¥ng (OpenAI)
- C√≤n quota kh√¥ng (Gemini)
- Network connection

### Model anti-cheat kh√¥ng ch√≠nh x√°c
**Gi·∫£i ph√°p:**
- Thu th·∫≠p th√™m training data
- Augment data (flip, rotate, brightness)
- Train th√™m epochs
- ƒêi·ªÅu ch·ªânh threshold

### CAT algorithm kh√¥ng adaptive
**Nguy√™n nh√¢n:**
- Kh√¥ng ƒë·ªß c√¢u h·ªèi ·ªü c√°c m·ª©c ƒë·ªô
- Difficulty kh√¥ng ƒë∆∞·ª£c g√°n ƒë√∫ng
- Bug trong code

---

## T√†i Li·ªáu Tham Kh·∫£o

### APIs
- [OpenAI API Docs](https://platform.openai.com/docs)
- [Google Gemini Docs](https://ai.google.dev/docs)
- [Hugging Face Inference](https://huggingface.co/docs/api-inference)
- [Ollama Docs](https://ollama.ai/docs)

### Machine Learning
- [TensorFlow.js Guide](https://www.tensorflow.org/js/guide)
- [IRT Theory](https://en.wikipedia.org/wiki/Item_response_theory)
- [Computer Vision with OpenCV](https://opencv.org/)

### Tutorials
- [Training Custom Models](https://www.tensorflow.org/tutorials)
- [Fine-tuning LLMs](https://huggingface.co/docs/transformers/training)
- [CAT Implementation](https://github.com/topics/computerized-adaptive-testing)

---

**L∆∞u √Ω**: Training models ƒë√≤i h·ªèi ki·∫øn th·ª©c v·ªÅ machine learning. N·∫øu ch∆∞a c√≥ kinh nghi·ªám, khuy·∫øn ngh·ªã d√πng c√°c models v√† APIs c√≥ s·∫µn.
