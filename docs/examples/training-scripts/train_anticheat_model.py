#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TRAINING ANTI-CHEAT MODEL
==========================

Script n√†y training model CNN ƒë·ªÉ ph√°t hi·ªán h√†nh vi gian l·∫≠n t·ª´ webcam.

Y√äU C·∫¶U:
- Python 3.8+
- D·ªØ li·ªáu ƒë√£ thu th·∫≠p (t·ª´ collect_anticheat_data.py)
- Packages: tensorflow, opencv-python, numpy, scikit-learn

C√ÄI ƒê·∫∂T:
    pip install tensorflow opencv-python numpy scikit-learn matplotlib

S·ª¨ D·ª§NG:
    python train_anticheat_model.py

K·∫æT QU·∫¢:
- Model: models/anticheat_model.h5
- TensorFlow.js: models/anticheat_tfjs/
"""

import os
import sys
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
import matplotlib.pyplot as plt


def load_images_from_folder(folder, label, target_size=(224, 224)):
    """
    Load ·∫£nh t·ª´ folder v√† g√°n label
    
    Args:
        folder (str): ƒê∆∞·ªùng d·∫´n folder
        label (int): Label (0=normal, 1=cheat)
        target_size (tuple): K√≠ch th∆∞·ªõc ·∫£nh output
    
    Returns:
        images, labels: numpy arrays
    """
    images = []
    labels = []
    
    if not os.path.exists(folder):
        print(f"‚ö†Ô∏è C·∫£nh b√°o: Folder kh√¥ng t·ªìn t·∫°i: {folder}")
        return np.array([]), np.array([])
    
    files = [f for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]
    total = len(files)
    
    print(f"üìÇ ƒêang load {total} ·∫£nh t·ª´ {folder}...")
    
    for idx, filename in enumerate(files):
        filepath = os.path.join(folder, filename)
        
        try:
            # ƒê·ªçc ·∫£nh
            img = cv2.imread(filepath)
            if img is None:
                print(f"   ‚ö†Ô∏è B·ªè qua file l·ªói: {filename}")
                continue
            
            # Resize
            img = cv2.resize(img, target_size)
            
            # Convert BGR to RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # Normalize [0, 1]
            img = img.astype(np.float32) / 255.0
            
            images.append(img)
            labels.append(label)
            
            # Progress
            if (idx + 1) % 100 == 0:
                print(f"   ‚úÖ ƒê√£ load: {idx + 1}/{total}")
                
        except Exception as e:
            print(f"   ‚ùå L·ªói khi load {filename}: {e}")
            continue
    
    print(f"‚úÖ Ho√†n th√†nh! Load ƒë∆∞·ª£c {len(images)} ·∫£nh\n")
    
    return np.array(images), np.array(labels)


def create_model(input_shape=(224, 224, 3)):
    """
    T·∫°o CNN model cho anti-cheat detection
    
    Args:
        input_shape (tuple): Shape c·ªßa input image
    
    Returns:
        model: Keras model
    """
    model = keras.Sequential([
        # Input
        layers.Input(shape=input_shape),
        
        # Block 1
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 2
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 3
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Classifier
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')  # Binary classification
    ])
    
    return model


def plot_training_history(history, output_path='models/training_history.png'):
    """V·∫Ω bi·ªÉu ƒë·ªì training history"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Loss
    ax1.plot(history.history['loss'], label='Training Loss')
    ax1.plot(history.history['val_loss'], label='Validation Loss')
    ax1.set_title('Model Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True)
    
    # Accuracy
    ax2.plot(history.history['accuracy'], label='Training Accuracy')
    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax2.set_title('Model Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig(output_path)
    print(f"üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {output_path}")


def main():
    """H√†m ch√≠nh"""
    print("="*70)
    print("ü§ñ TRAINING ANTI-CHEAT MODEL")
    print("="*70)
    print()
    
    # C·∫•u h√¨nh
    DATA_DIR = "data/anticheat_training"
    NORMAL_DIR = os.path.join(DATA_DIR, "normal")
    CHEAT_DIR = os.path.join(DATA_DIR, "cheat")
    MODEL_DIR = "models"
    
    # T·∫°o folder models
    os.makedirs(MODEL_DIR, exist_ok=True)
    
    # Ki·ªÉm tra d·ªØ li·ªáu
    print("üîç KI·ªÇM TRA D·ªÆ LI·ªÜU...")
    print("-"*70)
    
    if not os.path.exists(NORMAL_DIR) or not os.path.exists(CHEAT_DIR):
        print("‚ùå L·ªói: Ch∆∞a c√≥ d·ªØ li·ªáu training!")
        print(f"   C·∫ßn c√≥ folders:")
        print(f"   - {NORMAL_DIR}")
        print(f"   - {CHEAT_DIR}")
        print()
        print("üìù Ch·∫°y script sau ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu:")
        print("   python collect_anticheat_data.py")
        sys.exit(1)
    
    normal_count = len([f for f in os.listdir(NORMAL_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))])
    cheat_count = len([f for f in os.listdir(CHEAT_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))])
    
    print(f"‚úÖ T√¨m th·∫•y d·ªØ li·ªáu:")
    print(f"   - Normal: {normal_count} ·∫£nh")
    print(f"   - Cheat:  {cheat_count} ·∫£nh")
    print(f"   - Total:  {normal_count + cheat_count} ·∫£nh")
    print()
    
    if normal_count < 100 or cheat_count < 100:
        print("‚ö†Ô∏è C·∫£nh b√°o: D·ªØ li·ªáu √≠t, model c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c!")
        print("   Khuy·∫øn ngh·ªã: √çt nh·∫•t 500 ·∫£nh m·ªói lo·∫°i")
        response = input("   V·∫´n mu·ªën ti·∫øp t·ª•c? (y/n): ")
        if response.lower() != 'y':
            print("‚ùå D·ª´ng training.")
            sys.exit(0)
        print()
    
    # Load d·ªØ li·ªáu
    print("üì• LOAD D·ªÆ LI·ªÜU...")
    print("-"*70)
    
    X_normal, y_normal = load_images_from_folder(NORMAL_DIR, label=0)
    X_cheat, y_cheat = load_images_from_folder(CHEAT_DIR, label=1)
    
    # Combine v√† shuffle
    X = np.concatenate([X_normal, X_cheat])
    y = np.concatenate([y_normal, y_cheat])
    X, y = shuffle(X, y, random_state=42)
    
    print(f"üìä Dataset final:")
    print(f"   - Shape: {X.shape}")
    print(f"   - Normal: {np.sum(y == 0)} samples")
    print(f"   - Cheat:  {np.sum(y == 1)} samples")
    print()
    
    # Split train/val/test
    print("‚úÇÔ∏è CHIA D·ªÆ LI·ªÜU...")
    print("-"*70)
    
    # Train 70%, Val 15%, Test 15%
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    print(f"‚úÖ ƒê√£ chia:")
    print(f"   - Training:   {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)")
    print(f"   - Validation: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)")
    print(f"   - Test:       {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)")
    print()
    
    # T·∫°o model
    print("üèóÔ∏è T·∫†O MODEL...")
    print("-"*70)
    
    model = create_model()
    model.summary()
    print()
    
    # Compile
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy', 
                 keras.metrics.Precision(name='precision'),
                 keras.metrics.Recall(name='recall')]
    )
    
    # Callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            os.path.join(MODEL_DIR, 'best_model.h5'),
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        )
    ]
    
    # Training
    print("üéØ B·∫ÆT ƒê·∫¶U TRAINING...")
    print("-"*70)
    print("‚è≥ ƒê·ª£i m·ªôt l√°t, qu√° tr√¨nh c√≥ th·ªÉ m·∫•t 10-30 ph√∫t...")
    print()
    
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=50,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    
    print()
    print("‚úÖ TRAINING HO√ÄN T·∫§T!")
    print()
    
    # Evaluate
    print("üìä ƒê√ÅNH GI√Å MODEL...")
    print("-"*70)
    
    train_results = model.evaluate(X_train, y_train, verbose=0)
    val_results = model.evaluate(X_val, y_val, verbose=0)
    test_results = model.evaluate(X_test, y_test, verbose=0)
    
    print(f"üìà K·∫øt qu·∫£:")
    print(f"   Training Set:")
    print(f"      Loss:      {train_results[0]:.4f}")
    print(f"      Accuracy:  {train_results[1]:.4f}")
    print(f"      Precision: {train_results[2]:.4f}")
    print(f"      Recall:    {train_results[3]:.4f}")
    print()
    print(f"   Validation Set:")
    print(f"      Loss:      {val_results[0]:.4f}")
    print(f"      Accuracy:  {val_results[1]:.4f}")
    print(f"      Precision: {val_results[2]:.4f}")
    print(f"      Recall:    {val_results[3]:.4f}")
    print()
    print(f"   Test Set:")
    print(f"      Loss:      {test_results[0]:.4f}")
    print(f"      Accuracy:  {test_results[1]:.4f}")
    print(f"      Precision: {test_results[2]:.4f}")
    print(f"      Recall:    {test_results[3]:.4f}")
    print()
    
    # L∆∞u model
    print("üíæ L∆ØU MODEL...")
    print("-"*70)
    
    model_path = os.path.join(MODEL_DIR, 'anticheat_model.h5')
    model.save(model_path)
    print(f"‚úÖ ƒê√£ l∆∞u Keras model: {model_path}")
    
    # V·∫Ω bi·ªÉu ƒë·ªì
    plot_training_history(history, os.path.join(MODEL_DIR, 'training_history.png'))
    
    # Convert sang TensorFlow.js
    print()
    print("üîÑ CONVERT SANG TENSORFLOW.JS...")
    print("-"*70)
    
    tfjs_path = os.path.join(MODEL_DIR, 'anticheat_tfjs')
    
    try:
        import tensorflowjs as tfjs
        tfjs.converters.save_keras_model(model, tfjs_path)
        print(f"‚úÖ ƒê√£ convert th√†nh c√¥ng: {tfjs_path}")
        print()
        print(f"üìÅ Files TensorFlow.js:")
        for file in os.listdir(tfjs_path):
            print(f"   - {file}")
    except ImportError:
        print("‚ö†Ô∏è Ch∆∞a c√†i tensorflowjs!")
        print("   C√†i ƒë·∫∑t: pip install tensorflowjs")
        print("   Sau ƒë√≥ ch·∫°y:")
        print(f"   tensorflowjs_converter --input_format=keras {model_path} {tfjs_path}")
    
    # H∆∞·ªõng d·∫´n ti·∫øp theo
    print()
    print("="*70)
    print("üéâ HO√ÄN T·∫§T!")
    print("="*70)
    print()
    print("üìù B∆Ø·ªöC TI·∫æP THEO:")
    print("   1. Copy folder models/anticheat_tfjs/ v√†o:")
    print("      Intelligence-Test/public/models/anticheat-custom/")
    print()
    print("   2. Update code trong src/services/antiCheatService.ts:")
    print("      const model = await tf.loadLayersModel('/models/anticheat-custom/model.json');")
    print()
    print("   3. Restart app v√† test!")
    print()
    print("üí° TIP: Test accuracy > 90% l√† t·ªët. N·∫øu th·∫•p h∆°n, thu th·∫≠p th√™m d·ªØ li·ªáu.")
    print()


if __name__ == '__main__':
    main()
