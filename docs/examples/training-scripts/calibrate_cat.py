#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CALIBRATE CAT ALGORITHM - ƒê·ªò KH√ì C√ÇU H·ªéI
==========================================

Script n√†y calibrate ƒë·ªô kh√≥ c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·ª´ h·ªçc sinh.

Y√äU C·∫¶U:
- Python 3.8+
- File CSV v·ªõi responses c·ªßa h·ªçc sinh
- Packages: pandas, numpy, scipy

C√ÄI ƒê·∫∂T:
    pip install pandas numpy scipy

FORMAT FILE INPUT (responses.csv):
    student_id,question_id,correct
    S001,Q001,1
    S001,Q002,0
    S002,Q001,1
    ...

C√ÅCH L·∫§Y D·ªÆ LI·ªÜU:
1. V√†o Analytics Dashboard trong app
2. Export "Student Responses" d∆∞·ªõi d·∫°ng CSV
3. ƒê·∫∑t t√™n file: responses.csv
4. Ch·∫°y script n√†y

S·ª¨ D·ª§NG:
    python calibrate_cat.py responses.csv
"""

import sys
import pandas as pd
import numpy as np
from scipy.optimize import minimize
import warnings
warnings.filterwarnings('ignore')


def simple_calibration(df):
    """
    Calibration ƒë∆°n gi·∫£n: difficulty = 1 - t·ª∑ l·ªá ƒë√∫ng
    
    Ph∆∞∆°ng ph√°p n√†y kh√¥ng c·∫ßn training ph·ª©c t·∫°p, ph√π h·ª£p cho:
    - √çt d·ªØ li·ªáu (< 100 responses/question)
    - C·∫ßn k·∫øt qu·∫£ nhanh
    - ƒê·ªô ch√≠nh x√°c v·ª´a ph·∫£i
    
    Args:
        df: DataFrame v·ªõi columns [student_id, question_id, correct]
    
    Returns:
        DataFrame v·ªõi difficulty cho t·ª´ng c√¢u h·ªèi
    """
    print("üìä CALIBRATION ƒê∆†N GI·∫¢N (T·ª∑ l·ªá ƒë√∫ng)")
    print("-"*70)
    
    # T√≠nh t·ª∑ l·ªá ƒë√∫ng cho m·ªói c√¢u h·ªèi
    question_stats = df.groupby('question_id').agg({
        'correct': ['mean', 'count']
    }).reset_index()
    
    question_stats.columns = ['question_id', 'correct_rate', 'n_attempts']
    
    # Difficulty = 1 - correct_rate
    # C√†ng nhi·ªÅu ng∆∞·ªùi ƒë√∫ng (correct_rate cao) ‚Üí difficulty th·∫•p
    question_stats['difficulty'] = 1 - question_stats['correct_rate']
    
    # Normalize v·ªÅ range [0, 1]
    min_diff = question_stats['difficulty'].min()
    max_diff = question_stats['difficulty'].max()
    
    if max_diff > min_diff:
        question_stats['difficulty_normalized'] = (
            (question_stats['difficulty'] - min_diff) / (max_diff - min_diff)
        )
    else:
        question_stats['difficulty_normalized'] = 0.5
    
    # Ph√¢n lo·∫°i
    def classify_difficulty(diff):
        if diff < 0.3:
            return 'Easy'
        elif diff < 0.7:
            return 'Medium'
        else:
            return 'Hard'
    
    question_stats['category'] = question_stats['difficulty_normalized'].apply(classify_difficulty)
    
    return question_stats


def irt_calibration(df):
    """
    Calibration n√¢ng cao: IRT 1PL (Rasch Model)
    
    Ph∆∞∆°ng ph√°p n√†y ch√≠nh x√°c h∆°n nh∆∞ng c·∫ßn:
    - Nhi·ªÅu d·ªØ li·ªáu (> 100 responses/question)
    - Th·ªùi gian t√≠nh to√°n l√¢u h∆°n
    
    Args:
        df: DataFrame v·ªõi columns [student_id, question_id, correct]
    
    Returns:
        DataFrame v·ªõi difficulty cho t·ª´ng c√¢u h·ªèi
    """
    print("üéØ CALIBRATION N√ÇNG CAO (IRT 1PL)")
    print("-"*70)
    
    # Map IDs to indices
    students = df['student_id'].unique()
    questions = df['question_id'].unique()
    
    student_map = {s: i for i, s in enumerate(students)}
    question_map = {q: i for i, q in enumerate(questions)}
    
    df['student_idx'] = df['student_id'].map(student_map)
    df['question_idx'] = df['question_id'].map(question_map)
    
    n_students = len(students)
    n_questions = len(questions)
    
    print(f"   S·ªë h·ªçc sinh:  {n_students}")
    print(f"   S·ªë c√¢u h·ªèi:   {n_questions}")
    print(f"   S·ªë responses: {len(df)}")
    print()
    
    # Kh·ªüi t·∫°o parameters
    # [abilities (students), difficulties (questions)]
    initial_params = np.random.randn(n_students + n_questions) * 0.1
    
    def rasch_probability(ability, difficulty):
        """X√°c su·∫•t tr·∫£ l·ªùi ƒë√∫ng theo Rasch model"""
        return 1 / (1 + np.exp(-(ability - difficulty)))
    
    def log_likelihood(params):
        """H√†m log-likelihood ƒë·ªÉ t·ªëi ∆∞u"""
        abilities = params[:n_students]
        difficulties = params[n_students:]
        
        ll = 0
        for _, row in df.iterrows():
            s_idx = row['student_idx']
            q_idx = row['question_idx']
            correct = row['correct']
            
            prob = rasch_probability(abilities[s_idx], difficulties[q_idx])
            prob = np.clip(prob, 1e-10, 1 - 1e-10)  # Tr√°nh log(0)
            
            ll += correct * np.log(prob) + (1 - correct) * np.log(1 - prob)
        
        return -ll  # Negative v√¨ minimize
    
    # Optimize
    print("‚è≥ ƒêang t·ªëi ∆∞u parameters...")
    print("   (C√≥ th·ªÉ m·∫•t v√†i ph√∫t...)")
    
    result = minimize(
        log_likelihood,
        initial_params,
        method='L-BFGS-B',
        options={'maxiter': 1000, 'disp': False}
    )
    
    if not result.success:
        print("‚ö†Ô∏è C·∫£nh b√°o: Optimization kh√¥ng h·ªôi t·ª• ho√†n to√†n")
        print(f"   Message: {result.message}")
    
    # Extract parameters
    abilities = result.x[:n_students]
    difficulties = result.x[n_students:]
    
    # Normalize difficulties v·ªÅ [0, 1]
    min_diff = difficulties.min()
    max_diff = difficulties.max()
    
    if max_diff > min_diff:
        normalized_difficulties = (difficulties - min_diff) / (max_diff - min_diff)
    else:
        normalized_difficulties = np.full_like(difficulties, 0.5)
    
    # T·∫°o DataFrame k·∫øt qu·∫£
    results = pd.DataFrame({
        'question_id': questions,
        'difficulty_raw': difficulties,
        'difficulty_normalized': normalized_difficulties
    })
    
    # Ph√¢n lo·∫°i
    def classify_difficulty(diff):
        if diff < 0.3:
            return 'Easy'
        elif diff < 0.7:
            return 'Medium'
        else:
            return 'Hard'
    
    results['category'] = results['difficulty_normalized'].apply(classify_difficulty)
    
    # T√≠nh stats
    question_counts = df.groupby('question_id').size().reset_index(name='n_attempts')
    results = results.merge(question_counts, on='question_id')
    
    return results


def main():
    """H√†m ch√≠nh"""
    print("="*70)
    print("üéØ CALIBRATE CAT ALGORITHM - ƒê·ªò KH√ì C√ÇU H·ªéI")
    print("="*70)
    print()
    
    # Ki·ªÉm tra arguments
    if len(sys.argv) < 2:
        print("‚ùå L·ªói: Thi·∫øu file d·ªØ li·ªáu!")
        print()
        print("S·ª≠ d·ª•ng:")
        print("   python calibrate_cat.py <file_responses.csv>")
        print()
        print("V√≠ d·ª•:")
        print("   python calibrate_cat.py responses.csv")
        print()
        sys.exit(1)
    
    input_file = sys.argv[1]
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    try:
        df = pd.read_csv(input_file)
    except FileNotFoundError:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file: {input_file}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file: {e}")
        sys.exit(1)
    
    print(f"üìÇ ƒêang x·ª≠ l√Ω file: {input_file}")
    print()
    
    # Ki·ªÉm tra columns
    required_columns = ['student_id', 'question_id', 'correct']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"‚ùå L·ªói: File thi·∫øu columns: {missing_columns}")
        print()
        print("File c·∫ßn c√≥ format:")
        print("   student_id,question_id,correct")
        print("   S001,Q001,1")
        print("   S001,Q002,0")
        print("   ...")
        sys.exit(1)
    
    # Stats
    print("üìä TH√îNG TIN D·ªÆ LI·ªÜU:")
    print("-"*70)
    print(f"   T·ªïng responses:  {len(df)}")
    print(f"   S·ªë h·ªçc sinh:     {df['student_id'].nunique()}")
    print(f"   S·ªë c√¢u h·ªèi:      {df['question_id'].nunique()}")
    print(f"   T·ª∑ l·ªá ƒë√∫ng:      {df['correct'].mean():.2%}")
    print()
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·ªß kh√¥ng
    responses_per_question = len(df) / df['question_id'].nunique()
    
    if responses_per_question < 30:
        print("‚ö†Ô∏è C·∫¢NH B√ÅO: D·ªØ li·ªáu √≠t!")
        print(f"   Trung b√¨nh: {responses_per_question:.1f} responses/c√¢u h·ªèi")
        print("   Khuy·∫øn ngh·ªã: √çt nh·∫•t 50-100 responses/c√¢u h·ªèi")
        print("   ‚Üí S·ª≠ d·ª•ng calibration ƒë∆°n gi·∫£n")
        print()
        use_simple = True
    elif responses_per_question < 100:
        print("üí° G·ª£i √Ω: C√≥ th·ªÉ d√πng c·∫£ 2 ph∆∞∆°ng ph√°p")
        print(f"   Trung b√¨nh: {responses_per_question:.1f} responses/c√¢u h·ªèi")
        print()
        choice = input("   Ch·ªçn ph∆∞∆°ng ph√°p (1=ƒê∆°n gi·∫£n, 2=IRT n√¢ng cao, 3=C·∫£ hai): ")
        use_simple = choice != '2'
        use_irt = choice in ['2', '3']
    else:
        print("‚úÖ D·ªØ li·ªáu t·ªët! S·ª≠ d·ª•ng IRT n√¢ng cao")
        print(f"   Trung b√¨nh: {responses_per_question:.1f} responses/c√¢u h·ªèi")
        print()
        use_simple = False
        use_irt = True
    
    # Calibrate
    results_list = []
    
    if use_simple or not 'use_irt' in locals():
        print()
        results_simple = simple_calibration(df)
        results_simple.to_csv('difficulties_simple.csv', index=False)
        print(f"‚úÖ ƒê√£ l∆∞u: difficulties_simple.csv")
        results_list.append(('Simple', results_simple))
    
    if 'use_irt' in locals() and use_irt:
        print()
        results_irt = irt_calibration(df)
        results_irt.to_csv('difficulties_irt.csv', index=False)
        print(f"‚úÖ ƒê√£ l∆∞u: difficulties_irt.csv")
        results_list.append(('IRT', results_irt))
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    print()
    print("="*70)
    print("üìä K·∫æT QU·∫¢ CALIBRATION")
    print("="*70)
    
    for method_name, results in results_list:
        print()
        print(f"üìà Ph∆∞∆°ng ph√°p: {method_name}")
        print("-"*70)
        
        # Stats
        easy = (results['category'] == 'Easy').sum()
        medium = (results['category'] == 'Medium').sum()
        hard = (results['category'] == 'Hard').sum()
        
        print(f"   Ph√¢n b·ªë ƒë·ªô kh√≥:")
        print(f"      Easy:   {easy} c√¢u ({easy/len(results)*100:.1f}%)")
        print(f"      Medium: {medium} c√¢u ({medium/len(results)*100:.1f}%)")
        print(f"      Hard:   {hard} c√¢u ({hard/len(results)*100:.1f}%)")
        print()
        
        # Sample
        print("   Sample (5 c√¢u ƒë·∫ßu):")
        display_cols = ['question_id', 'difficulty_normalized', 'category']
        if 'n_attempts' in results.columns:
            display_cols.append('n_attempts')
        print(results[display_cols].head().to_string(index=False))
    
    # H∆∞·ªõng d·∫´n ti·∫øp theo
    print()
    print("="*70)
    print("üìù B∆Ø·ªöC TI·∫æP THEO:")
    print("="*70)
    print()
    print("1. M·ªü file CSV v·ª´a t·∫°o (difficulties_*.csv)")
    print("2. V√†o app ‚Üí Question Bank")
    print("3. Update ƒë·ªô kh√≥ (difficulty_normalized) cho t·ª´ng c√¢u h·ªèi")
    print()
    print("üí° TIP:")
    print("   - Easy (0.0-0.3): C√¢u d·ªÖ cho h·ªçc sinh y·∫øu")
    print("   - Medium (0.3-0.7): C√¢u trung b√¨nh")
    print("   - Hard (0.7-1.0): C√¢u kh√≥ cho h·ªçc sinh gi·ªèi")
    print()
    print("   H·ªá th·ªëng CAT s·∫Ω t·ª± ƒë·ªông ch·ªçn c√¢u ph√π h·ª£p v·ªõi t·ª´ng h·ªçc sinh!")
    print()


if __name__ == '__main__':
    main()
